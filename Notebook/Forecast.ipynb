{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10737e04",
   "metadata": {},
   "source": [
    "# Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1c92811d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: c:\\Users\\Admin\\OneDrive\\Máy tính\\Code\\Project Python for Data\\PythonProject\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1. Thư mục Notebook hiện tại\n",
    "current_dir = Path.cwd()\n",
    "\n",
    "# 2. Thư mục project_root là cha của Notebook (chứa folder Module, Clean_Data_2023-2025, ...)\n",
    "project_root_dir = current_dir.parent\n",
    "\n",
    "# 3. Thêm project_root vào sys.path để import Module.*\n",
    "if str(project_root_dir) not in sys.path:\n",
    "    sys.path.append(str(project_root_dir))\n",
    "\n",
    "print(f\"Project root: {project_root_dir}\")\n",
    "\n",
    "from Module.Load_Data import CleanDataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e818f251",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc1901eb",
   "metadata": {},
   "source": [
    "# Dự báo theo môn học"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238bff51",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9b4921",
   "metadata": {},
   "source": [
    "# Dự báo theo tỉ lệ tổ hợp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9d919841",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from Module.Load_Data import CleanDataLoader\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "def load_all_block_analysis_with_features(\n",
    "    clean_data: CleanDataLoader,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    - Đọc toàn bộ Export_Analysis_<BLOCK>.csv và Export_Distribution_<BLOCK>.csv\n",
    "      từ Block_Data để tạo bảng feature cho train.\n",
    "    - Thêm:\n",
    "        + n_students: số thí sinh của khối đó trong từng năm (từ distribution)\n",
    "        + total_students_year: tổng số thí sinh toàn năm (từ clean_data.get_total_students())\n",
    "        + share_in_year: tỉ lệ thí sinh khối đó / tổng thí sinh năm\n",
    "    \"\"\"\n",
    "\n",
    "    block_root: Path = clean_data.block_data_root\n",
    "    if not block_root.exists():\n",
    "        raise FileNotFoundError(f\"Block_Data folder không tồn tại: {block_root}\")\n",
    "\n",
    "    all_dfs = []\n",
    "\n",
    "    # Tiền tố folder: CleanData_<BLOCK> (ví dụ CleanData_A00)\n",
    "    folder_prefix = clean_data._block_data_f_prefix + \"_\"   # \"CleanData_\"\n",
    "\n",
    "    for sub in block_root.iterdir():\n",
    "        if not sub.is_dir():\n",
    "            continue\n",
    "\n",
    "        folder_name = sub.name\n",
    "        if not folder_name.startswith(folder_prefix):\n",
    "            continue\n",
    "\n",
    "        # Lấy mã khối: CleanData_A00 -> A00\n",
    "        block_code = folder_name[len(folder_prefix):]\n",
    "\n",
    "        # 1) Đọc file analysis\n",
    "        try:\n",
    "            df_anal = clean_data.get_block_data(block=block_code, kind=\"analysis\").copy()\n",
    "        except FileNotFoundError:\n",
    "            continue\n",
    "\n",
    "        if \"khoi\" not in df_anal.columns:\n",
    "            df_anal[\"khoi\"] = block_code\n",
    "\n",
    "        # 2) Đọc file distribution để đếm n_students theo năm\n",
    "        try:\n",
    "            df_dist = clean_data.get_block_data(block=block_code, kind=\"distribution\").copy()\n",
    "        except FileNotFoundError:\n",
    "            df_dist = pd.DataFrame(columns=[\"nam_hoc\", \"so_hoc_sinh\"])\n",
    "\n",
    "        if not df_dist.empty:\n",
    "            # Xác định cột đếm số học sinh\n",
    "            if \"so_hoc_sinh\" in df_dist.columns:\n",
    "                cnt_col = \"so_hoc_sinh\"\n",
    "                counts = (\n",
    "                    df_dist.groupby(\"nam_hoc\")[cnt_col]\n",
    "                           .sum()\n",
    "                           .reset_index(name=\"n_students\")\n",
    "                )\n",
    "            elif \"count\" in df_dist.columns:\n",
    "                cnt_col = \"count\"\n",
    "                counts = (\n",
    "                    df_dist.groupby(\"nam_hoc\")[cnt_col]\n",
    "                           .sum()\n",
    "                           .reset_index(name=\"n_students\")\n",
    "                )\n",
    "            else:\n",
    "                # fallback: chỉ đếm số dòng theo năm\n",
    "                counts = (\n",
    "                    df_dist.groupby(\"nam_hoc\")\n",
    "                           .size()\n",
    "                           .reset_index(name=\"n_students\")\n",
    "                )\n",
    "        else:\n",
    "            counts = pd.DataFrame(columns=[\"nam_hoc\", \"n_students\"])\n",
    "\n",
    "        # 3) Merge n_students vào analysis\n",
    "        df_merged = df_anal.merge(counts, on=\"nam_hoc\", how=\"left\")\n",
    "        all_dfs.append(df_merged)\n",
    "\n",
    "    if not all_dfs:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    block_analysis_all = pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "    # --- 4. Lấy tổng số thí sinh theo năm từ CleanDataLoader ---\n",
    "    #    File: Clean_Data_2023-2025/Export_Yearly_Total_Students.csv\n",
    "    #    Hàm: clean_data.get_total_students()\n",
    "    df_total = clean_data.get_total_students().copy()\n",
    "\n",
    "    # Chuẩn hoá tên cột tổng số thí sinh về 'total_students_year'\n",
    "    if \"total_students_year\" not in df_total.columns:\n",
    "        for cand in [\"tong_thi_sinh\", \"total_students\", \"so_thi_sinh\",\n",
    "                     \"tong_hoc_sinh\", \"n_students\"]:\n",
    "            if cand in df_total.columns:\n",
    "                df_total = df_total.rename(columns={cand: \"total_students_year\"})\n",
    "                break\n",
    "\n",
    "    if \"nam_hoc\" not in df_total.columns:\n",
    "        raise ValueError(\n",
    "            \"DataFrame từ get_total_students() phải có cột 'nam_hoc'.\"\n",
    "        )\n",
    "\n",
    "    # Merge tổng thí sinh năm vào bảng feature\n",
    "    block_analysis_all = block_analysis_all.merge(\n",
    "        df_total[[\"nam_hoc\", \"total_students_year\"]],\n",
    "        on=\"nam_hoc\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "    # 5) Tính share_in_year = n_students / total_students_year\n",
    "    if \"n_students\" in block_analysis_all.columns and \"total_students_year\" in block_analysis_all.columns:\n",
    "        block_analysis_all[\"share_in_year\"] = (\n",
    "            block_analysis_all[\"n_students\"] / block_analysis_all[\"total_students_year\"]\n",
    "        )\n",
    "\n",
    "    return block_analysis_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0dfa7c0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nam_hoc</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>mode</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>khoi</th>\n",
       "      <th>n_students</th>\n",
       "      <th>total_students_year</th>\n",
       "      <th>share_in_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023</td>\n",
       "      <td>20.774499</td>\n",
       "      <td>21.150</td>\n",
       "      <td>22.10</td>\n",
       "      <td>3.094093</td>\n",
       "      <td>0.45</td>\n",
       "      <td>29.35</td>\n",
       "      <td>A00</td>\n",
       "      <td>325902</td>\n",
       "      <td>1017584</td>\n",
       "      <td>0.320270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024</td>\n",
       "      <td>20.904633</td>\n",
       "      <td>21.300</td>\n",
       "      <td>22.80</td>\n",
       "      <td>3.380354</td>\n",
       "      <td>2.15</td>\n",
       "      <td>29.60</td>\n",
       "      <td>A00</td>\n",
       "      <td>343800</td>\n",
       "      <td>1061604</td>\n",
       "      <td>0.323850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025</td>\n",
       "      <td>19.384368</td>\n",
       "      <td>19.250</td>\n",
       "      <td>22.00</td>\n",
       "      <td>4.337350</td>\n",
       "      <td>1.70</td>\n",
       "      <td>30.00</td>\n",
       "      <td>A00</td>\n",
       "      <td>165467</td>\n",
       "      <td>1153072</td>\n",
       "      <td>0.143501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023</td>\n",
       "      <td>20.275288</td>\n",
       "      <td>20.450</td>\n",
       "      <td>20.50</td>\n",
       "      <td>3.339521</td>\n",
       "      <td>5.05</td>\n",
       "      <td>29.80</td>\n",
       "      <td>A01</td>\n",
       "      <td>315146</td>\n",
       "      <td>1017584</td>\n",
       "      <td>0.309700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024</td>\n",
       "      <td>20.473793</td>\n",
       "      <td>20.750</td>\n",
       "      <td>21.00</td>\n",
       "      <td>3.350473</td>\n",
       "      <td>5.20</td>\n",
       "      <td>29.60</td>\n",
       "      <td>A01</td>\n",
       "      <td>329761</td>\n",
       "      <td>1061604</td>\n",
       "      <td>0.310625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>2025</td>\n",
       "      <td>20.486105</td>\n",
       "      <td>20.750</td>\n",
       "      <td>21.50</td>\n",
       "      <td>2.593046</td>\n",
       "      <td>8.95</td>\n",
       "      <td>26.50</td>\n",
       "      <td>Y07</td>\n",
       "      <td>475</td>\n",
       "      <td>1153072</td>\n",
       "      <td>0.000412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>2025</td>\n",
       "      <td>19.659654</td>\n",
       "      <td>19.900</td>\n",
       "      <td>21.00</td>\n",
       "      <td>2.518257</td>\n",
       "      <td>13.25</td>\n",
       "      <td>25.25</td>\n",
       "      <td>Y08</td>\n",
       "      <td>260</td>\n",
       "      <td>1153072</td>\n",
       "      <td>0.000225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>2025</td>\n",
       "      <td>21.366093</td>\n",
       "      <td>21.750</td>\n",
       "      <td>22.75</td>\n",
       "      <td>2.741671</td>\n",
       "      <td>7.25</td>\n",
       "      <td>28.50</td>\n",
       "      <td>Y09</td>\n",
       "      <td>9493</td>\n",
       "      <td>1153072</td>\n",
       "      <td>0.008233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>2025</td>\n",
       "      <td>17.617708</td>\n",
       "      <td>16.925</td>\n",
       "      <td>16.60</td>\n",
       "      <td>2.435760</td>\n",
       "      <td>13.95</td>\n",
       "      <td>24.00</td>\n",
       "      <td>Y10</td>\n",
       "      <td>48</td>\n",
       "      <td>1153072</td>\n",
       "      <td>0.000042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>2025</td>\n",
       "      <td>18.666721</td>\n",
       "      <td>19.500</td>\n",
       "      <td>21.50</td>\n",
       "      <td>3.479088</td>\n",
       "      <td>11.00</td>\n",
       "      <td>27.50</td>\n",
       "      <td>Y11</td>\n",
       "      <td>61</td>\n",
       "      <td>1153072</td>\n",
       "      <td>0.000053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>157 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     nam_hoc       mean  median   mode       std    min    max khoi  \\\n",
       "0       2023  20.774499  21.150  22.10  3.094093   0.45  29.35  A00   \n",
       "1       2024  20.904633  21.300  22.80  3.380354   2.15  29.60  A00   \n",
       "2       2025  19.384368  19.250  22.00  4.337350   1.70  30.00  A00   \n",
       "3       2023  20.275288  20.450  20.50  3.339521   5.05  29.80  A01   \n",
       "4       2024  20.473793  20.750  21.00  3.350473   5.20  29.60  A01   \n",
       "..       ...        ...     ...    ...       ...    ...    ...  ...   \n",
       "152     2025  20.486105  20.750  21.50  2.593046   8.95  26.50  Y07   \n",
       "153     2025  19.659654  19.900  21.00  2.518257  13.25  25.25  Y08   \n",
       "154     2025  21.366093  21.750  22.75  2.741671   7.25  28.50  Y09   \n",
       "155     2025  17.617708  16.925  16.60  2.435760  13.95  24.00  Y10   \n",
       "156     2025  18.666721  19.500  21.50  3.479088  11.00  27.50  Y11   \n",
       "\n",
       "     n_students  total_students_year  share_in_year  \n",
       "0        325902              1017584       0.320270  \n",
       "1        343800              1061604       0.323850  \n",
       "2        165467              1153072       0.143501  \n",
       "3        315146              1017584       0.309700  \n",
       "4        329761              1061604       0.310625  \n",
       "..          ...                  ...            ...  \n",
       "152         475              1153072       0.000412  \n",
       "153         260              1153072       0.000225  \n",
       "154        9493              1153072       0.008233  \n",
       "155          48              1153072       0.000042  \n",
       "156          61              1153072       0.000053  \n",
       "\n",
       "[157 rows x 11 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data = CleanDataLoader(project_root=project_root_dir)\n",
    "\n",
    "df_block_features = load_all_block_analysis_with_features(clean_data=clean_data)\n",
    "df_block_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51498736",
   "metadata": {},
   "source": [
    "# Xử lý dữ liệu trước khi Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0b6bed22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nam_hoc</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>mode</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>khoi</th>\n",
       "      <th>n_students</th>\n",
       "      <th>total_students_year</th>\n",
       "      <th>share_in_year</th>\n",
       "      <th>khoi_group</th>\n",
       "      <th>year_idx</th>\n",
       "      <th>share_lag1</th>\n",
       "      <th>delta_share</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024</td>\n",
       "      <td>20.904633</td>\n",
       "      <td>21.300</td>\n",
       "      <td>22.80</td>\n",
       "      <td>3.380354</td>\n",
       "      <td>2.15</td>\n",
       "      <td>29.60</td>\n",
       "      <td>A00</td>\n",
       "      <td>343800</td>\n",
       "      <td>1061604</td>\n",
       "      <td>0.323850</td>\n",
       "      <td>A00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.320270</td>\n",
       "      <td>0.003579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025</td>\n",
       "      <td>19.384368</td>\n",
       "      <td>19.250</td>\n",
       "      <td>22.00</td>\n",
       "      <td>4.337350</td>\n",
       "      <td>1.70</td>\n",
       "      <td>30.00</td>\n",
       "      <td>A00</td>\n",
       "      <td>165467</td>\n",
       "      <td>1153072</td>\n",
       "      <td>0.143501</td>\n",
       "      <td>A00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.323850</td>\n",
       "      <td>-0.180349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024</td>\n",
       "      <td>20.473793</td>\n",
       "      <td>20.750</td>\n",
       "      <td>21.00</td>\n",
       "      <td>3.350473</td>\n",
       "      <td>5.20</td>\n",
       "      <td>29.60</td>\n",
       "      <td>A01</td>\n",
       "      <td>329761</td>\n",
       "      <td>1061604</td>\n",
       "      <td>0.310625</td>\n",
       "      <td>A01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.309700</td>\n",
       "      <td>0.000925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2025</td>\n",
       "      <td>18.878852</td>\n",
       "      <td>18.850</td>\n",
       "      <td>20.00</td>\n",
       "      <td>3.627548</td>\n",
       "      <td>5.50</td>\n",
       "      <td>29.75</td>\n",
       "      <td>A01</td>\n",
       "      <td>148930</td>\n",
       "      <td>1153072</td>\n",
       "      <td>0.129159</td>\n",
       "      <td>A01</td>\n",
       "      <td>2</td>\n",
       "      <td>0.310625</td>\n",
       "      <td>-0.181466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2024</td>\n",
       "      <td>20.531107</td>\n",
       "      <td>20.750</td>\n",
       "      <td>21.20</td>\n",
       "      <td>2.981836</td>\n",
       "      <td>3.20</td>\n",
       "      <td>29.55</td>\n",
       "      <td>B00</td>\n",
       "      <td>342291</td>\n",
       "      <td>1061604</td>\n",
       "      <td>0.322428</td>\n",
       "      <td>B00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.318946</td>\n",
       "      <td>0.003482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>2025</td>\n",
       "      <td>20.486105</td>\n",
       "      <td>20.750</td>\n",
       "      <td>21.50</td>\n",
       "      <td>2.593046</td>\n",
       "      <td>8.95</td>\n",
       "      <td>26.50</td>\n",
       "      <td>Y07</td>\n",
       "      <td>475</td>\n",
       "      <td>1153072</td>\n",
       "      <td>0.000412</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000791</td>\n",
       "      <td>-0.000379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>2025</td>\n",
       "      <td>19.659654</td>\n",
       "      <td>19.900</td>\n",
       "      <td>21.00</td>\n",
       "      <td>2.518257</td>\n",
       "      <td>13.25</td>\n",
       "      <td>25.25</td>\n",
       "      <td>Y08</td>\n",
       "      <td>260</td>\n",
       "      <td>1153072</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000412</td>\n",
       "      <td>-0.000186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>2025</td>\n",
       "      <td>21.366093</td>\n",
       "      <td>21.750</td>\n",
       "      <td>22.75</td>\n",
       "      <td>2.741671</td>\n",
       "      <td>7.25</td>\n",
       "      <td>28.50</td>\n",
       "      <td>Y09</td>\n",
       "      <td>9493</td>\n",
       "      <td>1153072</td>\n",
       "      <td>0.008233</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>0.008007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>2025</td>\n",
       "      <td>17.617708</td>\n",
       "      <td>16.925</td>\n",
       "      <td>16.60</td>\n",
       "      <td>2.435760</td>\n",
       "      <td>13.95</td>\n",
       "      <td>24.00</td>\n",
       "      <td>Y10</td>\n",
       "      <td>48</td>\n",
       "      <td>1153072</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>2</td>\n",
       "      <td>0.008233</td>\n",
       "      <td>-0.008191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>2025</td>\n",
       "      <td>18.666721</td>\n",
       "      <td>19.500</td>\n",
       "      <td>21.50</td>\n",
       "      <td>3.479088</td>\n",
       "      <td>11.00</td>\n",
       "      <td>27.50</td>\n",
       "      <td>Y11</td>\n",
       "      <td>61</td>\n",
       "      <td>1153072</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>148 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     nam_hoc       mean  median   mode       std    min    max khoi  \\\n",
       "1       2024  20.904633  21.300  22.80  3.380354   2.15  29.60  A00   \n",
       "2       2025  19.384368  19.250  22.00  4.337350   1.70  30.00  A00   \n",
       "4       2024  20.473793  20.750  21.00  3.350473   5.20  29.60  A01   \n",
       "5       2025  18.878852  18.850  20.00  3.627548   5.50  29.75  A01   \n",
       "7       2024  20.531107  20.750  21.20  2.981836   3.20  29.55  B00   \n",
       "..       ...        ...     ...    ...       ...    ...    ...  ...   \n",
       "152     2025  20.486105  20.750  21.50  2.593046   8.95  26.50  Y07   \n",
       "153     2025  19.659654  19.900  21.00  2.518257  13.25  25.25  Y08   \n",
       "154     2025  21.366093  21.750  22.75  2.741671   7.25  28.50  Y09   \n",
       "155     2025  17.617708  16.925  16.60  2.435760  13.95  24.00  Y10   \n",
       "156     2025  18.666721  19.500  21.50  3.479088  11.00  27.50  Y11   \n",
       "\n",
       "     n_students  total_students_year  share_in_year khoi_group  year_idx  \\\n",
       "1        343800              1061604       0.323850        A00         1   \n",
       "2        165467              1153072       0.143501        A00         2   \n",
       "4        329761              1061604       0.310625        A01         1   \n",
       "5        148930              1153072       0.129159        A01         2   \n",
       "7        342291              1061604       0.322428        B00         1   \n",
       "..          ...                  ...            ...        ...       ...   \n",
       "152         475              1153072       0.000412      OTHER         2   \n",
       "153         260              1153072       0.000225      OTHER         2   \n",
       "154        9493              1153072       0.008233      OTHER         2   \n",
       "155          48              1153072       0.000042      OTHER         2   \n",
       "156          61              1153072       0.000053      OTHER         2   \n",
       "\n",
       "     share_lag1  delta_share  \n",
       "1      0.320270     0.003579  \n",
       "2      0.323850    -0.180349  \n",
       "4      0.309700     0.000925  \n",
       "5      0.310625    -0.181466  \n",
       "7      0.318946     0.003482  \n",
       "..          ...          ...  \n",
       "152    0.000791    -0.000379  \n",
       "153    0.000412    -0.000186  \n",
       "154    0.000225     0.008007  \n",
       "155    0.008233    -0.008191  \n",
       "156    0.000042     0.000011  \n",
       "\n",
       "[148 rows x 15 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "df = df_block_features.copy()\n",
    "\n",
    "# 1. Chọn 8 khối chính + OTHER\n",
    "MAIN_BLOCKS = [\"A00\", \"A01\", \"B00\", \"C00\", \"D01\", \"D07\", \"D08\", \"D09\"]\n",
    "\n",
    "# Nếu khoi trong MAIN_BLOCKS thì giữ nguyên, ngược lại gom về OTHER\n",
    "df[\"khoi_group\"] = np.where(df[\"khoi\"].isin(MAIN_BLOCKS), df[\"khoi\"], \"OTHER\")\n",
    "\n",
    "# 2. Index thời gian (0, 1, 2, ...)\n",
    "df[\"year_idx\"] = df[\"nam_hoc\"] - df[\"nam_hoc\"].min()\n",
    "\n",
    "# 3. Sắp xếp theo nhóm khối + năm\n",
    "df = df.sort_values([\"khoi_group\", \"nam_hoc\"]).reset_index(drop=True)\n",
    "\n",
    "# 4. Tính lag & delta cho từng khoi_group\n",
    "df[\"share_lag1\"]   = df.groupby(\"khoi_group\")[\"share_in_year\"].shift(1)\n",
    "df[\"delta_share\"]  = df[\"share_in_year\"] - df[\"share_lag1\"]\n",
    "\n",
    "# 5. Bỏ các dòng không có lag (năm đầu tiên của mỗi khoi_group)\n",
    "df_model = df.dropna(subset=[\"share_lag1\"]).copy()\n",
    "\n",
    "# Các feature số dùng cho model\n",
    "base_features = [\n",
    "    \"year_idx\", \"mean\", \"median\", \"std\",\n",
    "    \"n_students\", \"total_students_year\",\n",
    "    \"share_lag1\", \"delta_share\"\n",
    "]\n",
    "\n",
    "df_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35aa234c",
   "metadata": {},
   "source": [
    "# Các mô hình dự báo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5840d935",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Linear Regression với Gradient Descent\n",
    "class LinearRegressionGD:\n",
    "    def __init__(\n",
    "        self,\n",
    "        lr: float = 0.01,\n",
    "        n_iter: int = 2000,\n",
    "        reg_lambda: float = 0.0,\n",
    "        verbose: bool = False,\n",
    "        random_state: int | None = None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Linear Regression (OLS) huấn luyện bằng Gradient Descent.\n",
    "\n",
    "        lr         : learning rate\n",
    "        n_iter     : số vòng lặp GD\n",
    "        reg_lambda : hệ số L2 regularization (0 = không regularize)\n",
    "        \"\"\"\n",
    "        self.lr = lr\n",
    "        self.n_iter = n_iter\n",
    "        self.reg_lambda = reg_lambda\n",
    "        self.verbose = verbose\n",
    "        self.random_state = random_state\n",
    "\n",
    "        self.W = None   # (d,)\n",
    "        self.b = None   # scalar\n",
    "\n",
    "    # Huấn luyện model với dữ liệu X, y\n",
    "    def fit(self, X: np.ndarray, y: np.ndarray):\n",
    "        X = np.asarray(X, dtype=float)\n",
    "        y = np.asarray(y, dtype=float).reshape(-1)\n",
    "\n",
    "        # Kích thước dữ liệu\n",
    "        N, d = X.shape\n",
    "\n",
    "        # Khởi tạo tham số\n",
    "        rng = np.random.default_rng(self.random_state)\n",
    "        self.W = rng.normal(loc=0.0, scale=0.01, size=d)\n",
    "        self.b = 0.0\n",
    "\n",
    "        # Thực hiện tìm Gradient Descent\n",
    "        for it in range(self.n_iter):\n",
    "            # y_hat = XW + b: Dự đoán\n",
    "            y_hat = X @ self.W + self.b  # (N,)\n",
    "\n",
    "            # residuals: đo sai số giữa dự đoán và thực tế ( Tính mất mát )\n",
    "            err = y_hat - y             # (N,)\n",
    "\n",
    "            # gradient (MSE + L2): \n",
    "            dW = (X.T @ err) / N + self.reg_lambda * self.W   # (d,)\n",
    "            db = err.mean()                                   # scalar\n",
    "\n",
    "            # update: Cập nhật tham số\n",
    "            self.W -= self.lr * dW\n",
    "            self.b -= self.lr * db\n",
    "\n",
    "            # Kiểm tra loss mỗi 200 vòng hoặc vòng cuối\n",
    "            if self.verbose and (it % 200 == 0 or it == self.n_iter - 1):\n",
    "                mse = (err ** 2).mean()\n",
    "                loss = mse + 0.5 * self.reg_lambda * np.sum(self.W ** 2)\n",
    "                # print(f\"Iter {it:4d} | loss = {loss:.8f}\")\n",
    "\n",
    "        return self\n",
    "\n",
    "    # Dự đoán với dữ liệu X mới\n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        if self.W is None:\n",
    "            raise ValueError(\"Model chưa được fit.\")\n",
    "        X = np.asarray(X, dtype=float)\n",
    "        return X @ self.W + self.b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "58f7f258",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "# One-hot cho khoi_group\n",
    "khoi_dummies = pd.get_dummies(df_model[\"khoi_group\"], prefix=\"khoi_group\")\n",
    "\n",
    "X_all = pd.concat([df_model[base_features], khoi_dummies], axis=1)\n",
    "y_all = df_model[\"share_in_year\"]\n",
    "\n",
    "# Train 2023–2024, Test 2025\n",
    "train_mask = df_model[\"nam_hoc\"] < 2025\n",
    "test_mask  = df_model[\"nam_hoc\"] == 2025\n",
    "\n",
    "X_train = X_all.loc[train_mask].values\n",
    "y_train = y_all.loc[train_mask].values\n",
    "\n",
    "X_test  = X_all.loc[test_mask].values\n",
    "y_test  = y_all.loc[test_mask].values\n",
    "\n",
    "# Scale feature để tránh overflow\n",
    "scaler_lin = StandardScaler()\n",
    "X_train_scaled = scaler_lin.fit_transform(X_train)\n",
    "X_test_scaled  = scaler_lin.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bbdcbadd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Linear] MAE = 0.0139, R² = 0.9711\n",
      "    nam_hoc khoi khoi_group  share_true  share_pred   abs_err\n",
      "2      2025  A00        A00    0.143501    0.154485  0.010984\n",
      "5      2025  A01        A01    0.129159    0.126685  0.002475\n",
      "8      2025  B00        B00    0.040420    0.068047  0.027627\n",
      "11     2025  C00        C00    0.268857    0.305421  0.036563\n",
      "14     2025  D01        D01    0.312425    0.333461  0.021037\n",
      "17     2025  D07        D07    0.314339    0.338312  0.023974\n",
      "20     2025  D08        D08    0.004081    0.022253  0.018171\n",
      "23     2025  D09        D09    0.063478    0.059584  0.003895\n",
      "72     2025  A02      OTHER    0.004950    0.029343  0.024393\n",
      "73     2025  A03      OTHER    0.014652    0.035335  0.020683\n"
     ]
    }
   ],
   "source": [
    "# Dùng class LinearRegressionGD bạn đã định nghĩa\n",
    "lin_model = LinearRegressionGD(\n",
    "    lr=1e-3,\n",
    "    n_iter=10000,\n",
    "    reg_lambda=1e-2,\n",
    "    verbose=True,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "lin_model.fit(X_train_scaled, y_train)\n",
    "y_pred_lin = lin_model.predict(X_test_scaled)\n",
    "\n",
    "# Đánh giá\n",
    "mae_lin = mean_absolute_error(y_test, y_pred_lin)\n",
    "r2_lin  = r2_score(y_test, y_pred_lin)\n",
    "\n",
    "print(f\"[Linear] MAE = {mae_lin:.4f}, R² = {r2_lin:.4f}\")\n",
    "\n",
    "df_eval_lin = df_model.loc[test_mask, [\"nam_hoc\", \"khoi\", \"khoi_group\"]].copy()\n",
    "df_eval_lin[\"share_true\"] = y_test\n",
    "df_eval_lin[\"share_pred\"] = y_pred_lin\n",
    "df_eval_lin[\"abs_err\"]    = (df_eval_lin[\"share_true\"] - df_eval_lin[\"share_pred\"]).abs()\n",
    "\n",
    "print(df_eval_lin.head(10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dc2372f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model2 = df_model.copy()\n",
    "\n",
    "# Chỉ lấy feature số\n",
    "X_cols = base_features\n",
    "for c in X_cols:\n",
    "    df_model2[c] = pd.to_numeric(df_model2[c], errors=\"coerce\")\n",
    "\n",
    "df_model2 = df_model2.replace([np.inf, -np.inf], np.nan).dropna(subset=X_cols + [\"khoi_group\", \"nam_hoc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "734117b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train/test theo năm (test = năm max, thường là 2025)\n",
    "test_year = int(df_model2[\"nam_hoc\"].max())\n",
    "train_df = df_model2[df_model2[\"nam_hoc\"] < test_year].copy()\n",
    "test_df  = df_model2[df_model2[\"nam_hoc\"] == test_year].copy()\n",
    "\n",
    "X_train = train_df[X_cols].values\n",
    "y_train = train_df[\"khoi_group\"].astype(str).values\n",
    "X_test  = test_df[X_cols].values\n",
    "y_test  = test_df[\"khoi_group\"].astype(str).values\n",
    "\n",
    "# Nếu train bị thiếu class thì báo luôn (tránh lỗi sklearn)\n",
    "if len(np.unique(y_train)) < 2:\n",
    "    raise ValueError(f\"Train set chỉ có {len(np.unique(y_train))} class. Kiểm tra lại dữ liệu train.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f2771c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiShareModel:\n",
    "    \"\"\"\n",
    "    Multinomial Logistic cho bài toán dự báo 'share' khi dữ liệu là 1 dòng / (khoi_group, năm).\n",
    "    Ý tưởng:\n",
    "      - Fit classifier y=khoi_group từ feature.\n",
    "      - Với 1 năm, mỗi khoi_group có 1 dòng -> lấy decision score của đúng class cho từng dòng.\n",
    "      - Softmax các score đó để ra phân phối share (tổng = 1).\n",
    "    \"\"\"\n",
    "    def __init__(self, feature_cols, random_state=42):\n",
    "        self.feature_cols = feature_cols\n",
    "        self.random_state = random_state\n",
    "        self.model = Pipeline([\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"lr\", LogisticRegression(\n",
    "                solver=\"saga\",\n",
    "                penalty=\"l2\",\n",
    "                class_weight=\"balanced\",\n",
    "                max_iter=10000,\n",
    "                random_state=random_state\n",
    "            ))\n",
    "        ])\n",
    "        self._fitted = False\n",
    "\n",
    "    @staticmethod\n",
    "    def _softmax(v):\n",
    "        v = np.asarray(v, dtype=float)\n",
    "        v = v - np.max(v)\n",
    "        e = np.exp(v)\n",
    "        return e / (e.sum() + 1e-12)\n",
    "\n",
    "    def _clean(self, df):\n",
    "        out = df.copy()\n",
    "        for c in self.feature_cols:\n",
    "            out[c] = pd.to_numeric(out[c], errors=\"coerce\")\n",
    "        out = out.replace([np.inf, -np.inf], np.nan).dropna(subset=self.feature_cols + [\"khoi_group\", \"nam_hoc\"])\n",
    "        out[\"nam_hoc\"] = out[\"nam_hoc\"].astype(int)\n",
    "        out[\"khoi_group\"] = out[\"khoi_group\"].astype(str)\n",
    "        return out\n",
    "\n",
    "    def fit(self, df_train):\n",
    "        df_train = self._clean(df_train)\n",
    "        X = df_train[self.feature_cols].values\n",
    "        y = df_train[\"khoi_group\"].values\n",
    "        if len(np.unique(y)) < 2:\n",
    "            raise ValueError(\"Train set chỉ có <2 class. Kiểm tra lại dữ liệu train.\")\n",
    "        self.model.fit(X, y)\n",
    "        self._fitted = True\n",
    "        return self\n",
    "\n",
    "    def predict_share_year(self, df_year):\n",
    "        if not self._fitted:\n",
    "            raise RuntimeError(\"Model chưa fit().\")\n",
    "\n",
    "        df_year = self._clean(df_year)\n",
    "        # giữ đúng order các khoi trong năm\n",
    "        groups = df_year[\"khoi_group\"].tolist()\n",
    "\n",
    "        lr = self.model.named_steps[\"lr\"]\n",
    "        classes = lr.classes_\n",
    "        class_to_idx = {c:i for i, c in enumerate(classes)}\n",
    "\n",
    "        X = df_year[self.feature_cols].values\n",
    "        Xs = self.model.named_steps[\"scaler\"].transform(X)\n",
    "        scores = lr.decision_function(Xs)\n",
    "\n",
    "        # Binary case: scores (n,) -> convert to (n,2)\n",
    "        if scores.ndim == 1:\n",
    "            scores = np.vstack([-scores, scores]).T\n",
    "\n",
    "        # lấy score theo đúng class của từng dòng\n",
    "        s = np.empty(len(groups), dtype=float)\n",
    "        for i, g in enumerate(groups):\n",
    "            s[i] = scores[i, class_to_idx[g]] if g in class_to_idx else -1e9\n",
    "\n",
    "        share = self._softmax(s)\n",
    "        out = pd.DataFrame({\"khoi_group\": groups, \"share_pred\": share})\n",
    "        out[\"share_pred\"] = out[\"share_pred\"] / out[\"share_pred\"].sum()\n",
    "        return out\n",
    "\n",
    "    def evaluate_year(self, df_all, year):\n",
    "        df_all = self._clean(df_all)\n",
    "        df_year = df_all[df_all[\"nam_hoc\"] == int(year)].copy()\n",
    "\n",
    "        df_true = (df_year.groupby(\"khoi_group\", as_index=False)[\"share_in_year\"]\n",
    "                   .mean().rename(columns={\"share_in_year\": \"share_true\"}))\n",
    "        df_pred = self.predict_share_year(df_year[[\"nam_hoc\",\"khoi_group\"] + self.feature_cols].copy())\n",
    "        df_pred = df_pred.rename(columns={\"share_pred\":\"share_pred\"})\n",
    "\n",
    "        df_eval = df_true.merge(df_pred, on=\"khoi_group\", how=\"outer\").fillna(0)\n",
    "        df_eval[\"abs_err\"] = (df_eval[\"share_true\"] - df_eval[\"share_pred\"]).abs()\n",
    "        mae = df_eval[\"abs_err\"].mean()\n",
    "        return df_eval.sort_values(\"abs_err\", ascending=False).reset_index(drop=True), mae\n",
    "\n",
    "    def build_features_for_next_year(self, df_all):\n",
    "        \"\"\"\n",
    "        Tạo feature cho năm (max_year+1) theo đúng logic notebook:\n",
    "          - year_idx = max(year_idx)+1\n",
    "          - share_lag1 = share_in_year năm cuối\n",
    "          - delta_share = share_in_year(last) - share_in_year(last-1)\n",
    "          - mean/median/std/n_students/total_students_year: copy từ năm cuối\n",
    "        \"\"\"\n",
    "        df_all = self._clean(df_all)\n",
    "        last_year = int(df_all[\"nam_hoc\"].max())\n",
    "        prev_year = last_year - 1\n",
    "\n",
    "        df_last = df_all[df_all[\"nam_hoc\"] == last_year].copy()\n",
    "        df_prev = df_all[df_all[\"nam_hoc\"] == prev_year][[\"khoi_group\",\"share_in_year\"]].copy()\n",
    "        df_prev = df_prev.rename(columns={\"share_in_year\":\"share_prev\"})\n",
    "\n",
    "        df_next = df_last.merge(df_prev, on=\"khoi_group\", how=\"left\")\n",
    "        df_next[\"share_lag1\"] = df_next[\"share_in_year\"]\n",
    "        df_next[\"delta_share\"] = df_next[\"share_in_year\"] - df_next[\"share_prev\"].fillna(df_next[\"share_in_year\"])\n",
    "        df_next[\"year_idx\"] = int(df_last[\"year_idx\"].max()) + 1\n",
    "        df_next[\"nam_hoc\"] = last_year + 1\n",
    "\n",
    "        # đảm bảo đủ feature_cols\n",
    "        for c in self.feature_cols:\n",
    "            if c not in df_next.columns:\n",
    "                df_next[c] = 0\n",
    "        df_next = df_next[[\"nam_hoc\",\"khoi_group\"] + self.feature_cols].copy()\n",
    "        return df_next\n",
    "\n",
    "    def forecast_next_year(self, df_all):\n",
    "        df_next = self.build_features_for_next_year(df_all)\n",
    "        return self.predict_share_year(df_next)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e27ff308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  khoi_group  share_true    share_pred   abs_err\n",
      "0        D07    0.314339  8.418048e-01  0.527466\n",
      "1        D01    0.312425  5.119076e-05  0.312373\n",
      "2        C00    0.268857  1.316907e-08  0.268857\n",
      "3        A00    0.143501  8.050070e-07  0.143500\n",
      "4        A01    0.129159  3.595567e-08  0.129159\n",
      "5      OTHER    0.039501  1.517424e-01  0.112241\n",
      "6        D09    0.063478  4.665389e-08  0.063478\n",
      "7        B00    0.040420  1.188579e-07  0.040420\n",
      "8      OTHER    0.039501  1.241538e-09  0.039501\n",
      "9      OTHER    0.039501  1.192279e-08  0.039501\n",
      "MAE MULTI: 0.0528\n",
      "  khoi_group    share_pred\n",
      "0        A00  8.037195e-05\n",
      "1        A01  1.886261e-06\n",
      "2        B00  3.822099e-06\n",
      "3        C00  2.817818e-07\n",
      "4        D01  3.856405e-07\n",
      "5        D07  7.471079e-01\n",
      "6        D08  7.796743e-06\n",
      "7        D09  1.272405e-07\n",
      "8      OTHER  4.373399e-06\n",
      "9      OTHER  2.644213e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# TRAIN/EVAL MULTI\n",
    "multi = MultiShareModel(feature_cols=base_features).fit(df_model)   # df_model đã dropna lag1\n",
    "eval_multi, mae_multi = multi.evaluate_year(df, year=df[\"nam_hoc\"].max())\n",
    "print(eval_multi.head(10))\n",
    "print(\"MAE MULTI:\", round(mae_multi, 4))\n",
    "\n",
    "pred_2026_multi = multi.forecast_next_year(df)\n",
    "print(pred_2026_multi.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26eb54f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "# ARIMA forecast cho share theo từng khoi_group\n",
    "class ArimaShareModel:\n",
    "    \"\"\"\n",
    "    ARIMA forecast cho share theo từng khoi_group.\n",
    "    - Fix warning bằng PeriodIndex(freq=\"Y\")\n",
    "    - Forecast từng group, clip >= 1e-9\n",
    "    - Normalize tổng share = 1\n",
    "    \"\"\"\n",
    "    def __init__(self, min_points_for_ar1=4):\n",
    "        self.min_points_for_ar1 = min_points_for_ar1\n",
    "\n",
    "    @staticmethod\n",
    "    def _to_series(sub_df):\n",
    "        years = sub_df[\"nam_hoc\"].astype(int).tolist()\n",
    "        vals = pd.to_numeric(sub_df[\"share_in_year\"], errors=\"coerce\").astype(float).tolist()\n",
    "        s = pd.Series(vals, index=pd.PeriodIndex(years, freq=\"Y\")).asfreq(\"Y\")\n",
    "        return s\n",
    "\n",
    "    def _forecast_one(self, s: pd.Series):\n",
    "        s = s.astype(float)\n",
    "        if len(s) < 2:\n",
    "            return float(s.iloc[-1])\n",
    "        order = (1,0,0) if len(s) >= self.min_points_for_ar1 else (0,0,0)\n",
    "        try:\n",
    "            res = ARIMA(s, order=order).fit()\n",
    "            return float(res.forecast(steps=1).iloc[0])\n",
    "        except Exception:\n",
    "            return float(s.iloc[-1])\n",
    "\n",
    "    def forecast_year(self, df_all, target_year):\n",
    "        df_all = df_all.copy()\n",
    "        df_all[\"nam_hoc\"] = df_all[\"nam_hoc\"].astype(int)\n",
    "        df_all[\"khoi_group\"] = df_all[\"khoi_group\"].astype(str)\n",
    "        df_all[\"share_in_year\"] = pd.to_numeric(df_all[\"share_in_year\"], errors=\"coerce\")\n",
    "        df_all = df_all.dropna(subset=[\"share_in_year\"])\n",
    "\n",
    "        preds = {}\n",
    "        for g, sub in df_all.groupby(\"khoi_group\"):\n",
    "            sub = sub.sort_values(\"nam_hoc\")\n",
    "            sub = sub[sub[\"nam_hoc\"] < int(target_year)]\n",
    "            if len(sub) == 0:\n",
    "                continue\n",
    "            s = self._to_series(sub)\n",
    "            yhat = self._forecast_one(s)\n",
    "            preds[g] = max(yhat, 1e-9)\n",
    "\n",
    "        pred = pd.Series(preds, name=f\"share_pred_{int(target_year)}\")\n",
    "        pred = pred / pred.sum()\n",
    "        return pred.reset_index().rename(columns={\"index\":\"khoi_group\"})\n",
    "\n",
    "    def evaluate_year(self, df_all, year):\n",
    "        year = int(year)\n",
    "        df_all = df_all.copy()\n",
    "        df_all[\"nam_hoc\"] = df_all[\"nam_hoc\"].astype(int)\n",
    "\n",
    "        df_true = df_all[df_all[\"nam_hoc\"] == year][[\"khoi_group\",\"share_in_year\"]].copy()\n",
    "        df_true = df_true.groupby(\"khoi_group\", as_index=False)[\"share_in_year\"].mean()\n",
    "        df_true = df_true.rename(columns={\"share_in_year\":\"share_true\"})\n",
    "\n",
    "        df_pred = self.forecast_year(df_all, target_year=year)\n",
    "        pred_col = f\"share_pred_{year}\"\n",
    "\n",
    "        df_eval = df_true.merge(df_pred, on=\"khoi_group\", how=\"outer\").fillna(0)\n",
    "        df_eval[\"abs_err\"] = (df_eval[\"share_true\"] - df_eval[pred_col]).abs()\n",
    "        mae = df_eval[\"abs_err\"].mean()\n",
    "        return df_eval.sort_values(\"abs_err\", ascending=False).reset_index(drop=True), mae\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d231da2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  khoi_group  share_true  share_pred_2025   abs_err\n",
      "0        D07    0.314339         0.184648  0.129690\n",
      "1        D01    0.312425         0.184078  0.128347\n",
      "2        C00    0.268857         0.142757  0.126101\n",
      "3        A00    0.143501         0.068976  0.074525\n",
      "4        A01    0.129159         0.066428  0.062731\n",
      "5        D08    0.004081         0.066093  0.062011\n",
      "6      OTHER    0.039501         0.101124  0.061623\n",
      "7        D09    0.063478         0.117214  0.053736\n",
      "8        B00    0.040420         0.068682  0.028262\n",
      "MAE ARIMA: 0.0808\n",
      "  khoi_group  share_pred_2026\n",
      "0        A00         0.080405\n",
      "1        A01         0.076512\n",
      "2        B00         0.069601\n",
      "3        C00         0.163539\n",
      "4        D01         0.207378\n",
      "5        D07         0.208117\n",
      "6        D08         0.063423\n",
      "7        D09         0.118222\n",
      "8      OTHER         0.012803\n"
     ]
    }
   ],
   "source": [
    "# TRAIN/EVAL ARIMA\n",
    "arima = ArimaShareModel()\n",
    "eval_arima, mae_arima = arima.evaluate_year(df, year=df[\"nam_hoc\"].max())\n",
    "print(eval_arima.head(10))\n",
    "print(\"MAE ARIMA:\", round(mae_arima, 4))\n",
    "\n",
    "pred_2026_arima = arima.forecast_year(df, target_year=df[\"nam_hoc\"].max() + 1)\n",
    "print(pred_2026_arima.head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
